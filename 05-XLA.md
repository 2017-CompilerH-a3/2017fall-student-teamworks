# XLA

## Project link

https://github.com/TensorflowXLABeginner/2017fall-student-teamworks

### Group Members

| Name | Github Account | ID         |
| ---- | -------------- | ---------- |
| 宋小牛  | Jeffery-Song   | PB15000301 |
| 王若冰  | MalcolmUnWang  | PB15121735 |
| 陈翊辉  | cyh-ustc       | PB15111656 |

## Introduction

**XLA** (Accelerated Linear Algebra)([github](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler)) is a domain-specific compiler for linear algebra that optimizes TensorFlow computations. The results are improvements in speed, memory usage, and portability on server and mobile platforms. Users can use XLA via JIT (just-in-time) compilation or AOT (ahead-of-time) compilation.

In this project, we will do a small research on XLA, which covers in

* What kind of acceleration can XLA do
* How does XLA do it
* Where does JIT and AOT came in

## Reference

[XLA Overview](https://www.tensorflow.org/performance/xla/)

[XLA - TensorFlow 编译器](http://developers.googleblog.cn/2017/03/xla-tensorflow.html)

[XLA Source Code](https://github.com/TensorflowXLABeginner/tensorflow/tree/master/tensorflow/compiler/xla)
